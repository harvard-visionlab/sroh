{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ipcl_vs_brains_wrsa.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZHasR9mXNRq7SPmJ9dQxG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/sroh/blob/main/2022/ipcl_vs_brains_wrsa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcRL2FwjtSZ3"
      },
      "outputs": [],
      "source": [
        "!wget -nc https://osf.io/8qcdp/download -O ObjectOrientationData.mat\n",
        "!wget -nc https://osf.io/49qeb/download -O InanimateObjectsData.mat\n",
        "!wget -nc https://osf.io/x9dz4/download -O InanimateObjects.zip\n",
        "!unzip InanimateObjects.zip\n",
        "!mkdir -p Stimuli \n",
        "!mv InanimateObjects ./Stimuli/InanimateObjects\n",
        "!wget -c https://raw.githubusercontent.com/harvard-visionlab/sroh/main/2022/feature_extractor.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_brain_data(dataset, brain_regions=['EarlyV', 'pOTC', 'aOTC']):\n",
        "    assert dataset in ['InanimateObjects', 'ObjectOrientation']\n",
        "    path = f'{dataset}Data.mat'\n",
        "    D = sio.loadmat(path, struct_as_record=False, squeeze_me=True)\n",
        "    rdms = {r: D['rdms'].__dict__[r] for r in brain_regions}\n",
        "    betas = {r: D['betas'].__dict__[r] for r in brain_regions}\n",
        "    reliability = {r: D['reliability'].__dict__[r] for r in brain_regions}\n",
        "    image_names = [f.strip() for f in D['image_names']]\n",
        "    return rdms, betas, reliability, image_names"
      ],
      "metadata": {
        "id": "xBhccI8UtlbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdms, betas, reliability, image_names = load_brain_data('InanimateObjects')\n",
        "for k,v in rdms.items(): print(k, v.shape)"
      ],
      "metadata": {
        "id": "KvjIV8wBt_IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for k,v in betas.items(): \n",
        "#   print(k, v.shape)\n",
        "#   for brain_subject in v:\n",
        "#     print(brain_subject.shape)"
      ],
      "metadata": {
        "id": "HhYSSm1Duika"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rdms, betas, reliability, image_names = load_brain_data('ObjectOrientation')\n",
        "# for k,v in rdms.items(): print(k, v.shape)"
      ],
      "metadata": {
        "id": "SwHaSb0ZuQ_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.metrics import r2_score\n",
        "from pdb import set_trace\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "\n",
        "default_alphas = np.concatenate([np.array([1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0]), np.logspace(1, 5, 50)])\n",
        "\n",
        "def leave_one_out_ridge(X, y, alphas=default_alphas, fit_intercept=True, normalize=True, mb=None):\n",
        "    '''\n",
        "        Construct predicted brain patterns by training on N-1 items, \n",
        "        and then predicting the held out item.\n",
        "        \n",
        "        X: model responses [numItems x numFeatures]\n",
        "        y: brain responses [numItems x numVoxels]\n",
        "    '''\n",
        "    n_items, n_features = X.shape\n",
        "    n_voxels = y.shape[1]\n",
        "    y_pred = np.zeros(y.shape)\n",
        "\n",
        "    ALPHAS = []\n",
        "    COEF_M = np.zeros((n_voxels, n_features))\n",
        "    INTERCEPT = []\n",
        "    for iter_count, test_idx in enumerate(progress_bar(range(n_items), total=n_items)):\n",
        "        train_idxs = np.ones(n_items) == True\n",
        "        train_idxs[test_idx] = False\n",
        "        test_idxs = ~train_idxs  \n",
        "\n",
        "        clf = RidgeCV(alphas=alphas, fit_intercept=fit_intercept)\n",
        "\n",
        "        if normalize:\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(X[train_idxs])\n",
        "            X_train = scaler.transform(X[train_idxs])\n",
        "            X_test = scaler.transform(X[test_idxs])        \n",
        "        else:\n",
        "            X_train = X[train_idxs]\n",
        "            X_test = X[test_idxs]\n",
        "              \n",
        "        clf.fit(X_train, y[train_idxs])\n",
        "        y_pred[test_idxs] = clf.predict(X_test)\n",
        "        \n",
        "        ALPHAS.append(clf.alpha_)\n",
        "        COEF_M += clf.coef_\n",
        "        INTERCEPT.append(clf.intercept_)\n",
        "\n",
        "    ALPHAS = np.stack(ALPHAS)\n",
        "    COEF_M /= iter_count\n",
        "    INTERCEPT = np.stack(INTERCEPT)\n",
        "    R2 = r2_score(y, y_pred, multioutput='raw_values')\n",
        "    \n",
        "    return {\n",
        "        \"n_items\": n_items,\n",
        "        \"n_features\": n_features,\n",
        "        \"n_voxels\": y.shape[1],\n",
        "        \"ALPHAS\": ALPHAS,\n",
        "        \"COEF_M\": COEF_M,\n",
        "        \"INTERCEPT\": INTERCEPT,\n",
        "        \"R2\": R2,\n",
        "        \"y_pred\": y_pred\n",
        "    }"
      ],
      "metadata": {
        "id": "SEjVyNxu2Kam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms \n",
        "from PIL import Image \n",
        "from natsort import natsorted \n",
        "from glob import glob \n",
        "from pathlib import Path \n",
        "from feature_extractor import FeatureExtractor\n",
        "\n",
        "def prepare_images(dataset='InanimateObjects', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "\n",
        "    # standard imagenet normalization\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        lambda x: Image.open(x),    # use PIL to open the image\n",
        "        transforms.Resize(224),     # resize shorted edge to 224 pixels\n",
        "        transforms.CenterCrop(224), # center crop if not square\n",
        "        transforms.ToTensor(),      # convert from RGB (HxWxC) to channels first torch tensor [CxHxW]\n",
        "        normalize                   # normalize by imagenet stats\n",
        "    ])\n",
        "    files = natsorted(glob(f'./Stimuli/{dataset}/*.jpg'))\n",
        "    file_names = [Path(f).name for f in files] \n",
        "    imgs = torch.stack([transform(f) for f in files])\n",
        "\n",
        "    return imgs\n",
        "\n",
        "def fit_encoding_model(betas, model_name='alexnet', layer_name='classifier.5',\n",
        "                       dataset='InanimateObjects', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "          \n",
        "    print(\"==> prepare images\")\n",
        "    imgs = prepare_images(dataset=dataset, mean=mean, std=std)\n",
        "    \n",
        "    print(\"==> load pretrained model\")\n",
        "    model = models.__dict__[model_name](pretrained=True)\n",
        "\n",
        "    print(\"==> extract activation map for the given layer\")\n",
        "    pred_rdms = {}\n",
        "    feat_rdms = {}\n",
        "    model.eval()   # <-- very important, freeze normalization stats, no dropout etc.\n",
        "    with FeatureExtractor(model, [layer_name]) as extractor:\n",
        "        features = extractor(imgs)\n",
        "        for layer_name,feat in features.items():\n",
        "            # retain spatial information, but flatten rows into a 1D feature vector\n",
        "            X = torch.flatten(feat, 1)\n",
        "            feat_rdm = 1 - np.corrcoef(X)\n",
        "            feat_rdms[layer_name] = feat_rdm\n",
        "            \n",
        "            print(f\"==> fitting ridge regression model ({layer_name}) (numFeatures={X.shape[1]})\")\n",
        "            results = leave_one_out_ridge(X, betas, fit_intercept=True, normalize=False)\n",
        "            \n",
        "            # compute the predicted neural RDM\n",
        "            pred_rdm = 1 - np.corrcoef(results['y_pred'])\n",
        "            pred_rdms[layer_name] = pred_rdm\n",
        "              \n",
        "            # now do something with the rdms, e.g., save them for our split-half analysis\n",
        "          \n",
        "    return pred_rdms, feat_rdms, results"
      ],
      "metadata": {
        "id": "morbezfKue3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "betas.keys()"
      ],
      "metadata": {
        "id": "b5pCgVe63wbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_betas = betas['pOTC'][0].transpose()\n",
        "sub_betas.shape"
      ],
      "metadata": {
        "id": "2At_mQhd5hgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_rdms, feat_rdms, results = fit_encoding_model(sub_betas, \n",
        "                                                   model_name='alexnet', \n",
        "                                                   layer_name='classifier.5',\n",
        "                                                   dataset='InanimateObjects', \n",
        "                                                   mean=[0.485, 0.456, 0.406], \n",
        "                                                   std=[0.229, 0.224, 0.225])\n",
        "results.keys()"
      ],
      "metadata": {
        "id": "o7NLl51u5k4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.keys()"
      ],
      "metadata": {
        "id": "-jJX026d5zeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['n_voxels'], results['n_features']"
      ],
      "metadata": {
        "id": "JUK-xMNc68_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['y_pred'].shape"
      ],
      "metadata": {
        "id": "tqrF6QIV6--Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results['R2']"
      ],
      "metadata": {
        "id": "v6f7fCsw7ESr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "\n",
        "sns.distplot(results['R2'])"
      ],
      "metadata": {
        "id": "_el0DrV27Wv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['COEF_M'].shape"
      ],
      "metadata": {
        "id": "hMDmCA3g7m3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys = results['COEF_M'].mean(axis=0)\n",
        "xs = list(range(len(ys)))\n",
        "sns.lineplot(xs, ys)"
      ],
      "metadata": {
        "id": "d3m5OZJC8TwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(results['COEF_M'].mean(axis=0))"
      ],
      "metadata": {
        "id": "bo5Ca6eb8ar6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qSBPW-Xc8zEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}