{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sroh_2022_feature_extraction_test_images.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "KIcnuCuhRexd"
      ],
      "authorship_tag": "ABX9TyOUvidp5UaiNUM1OurOvcV3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/sroh/blob/main/2022/sroh_2022_feature_extraction_test_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features For a Batch of Test Images"
      ],
      "metadata": {
        "id": "LfncMS5NRWmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloads"
      ],
      "metadata": {
        "id": "KIcnuCuhRexd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "djkWJIczfM9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://www.dropbox.com/s/wubxg3tslwruqpb/face_stimuli_png.zip\n",
        "!wget -c https://raw.githubusercontent.com/harvard-visionlab/sroh/main/2022/imagenet_categories.py\n",
        "!wget -c https://raw.githubusercontent.com/harvard-visionlab/sroh/main/2022/feature_extractor.py"
      ],
      "metadata": {
        "id": "zVIdMnaFRrGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip face_stimuli_png.zip"
      ],
      "metadata": {
        "id": "zuLe8ADhSGGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob \n",
        "\n",
        "files = sorted(glob('./face_stimuli_png/*.png'))\n",
        "files"
      ],
      "metadata": {
        "id": "05KyNg8fW31s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image \n",
        "\n",
        "Image.open('./face_stimuli_png/blurred_white_male.png')"
      ],
      "metadata": {
        "id": "kPRuvjW4SMYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rHFdhfmfWLjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# do feature extraction and comparison"
      ],
      "metadata": {
        "id": "21Fy4VddWNdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize(224),\n",
        "  transforms.CenterCrop(224), \n",
        "  transforms.ToTensor(),\n",
        "  normalize,\n",
        "])\n",
        "transform"
      ],
      "metadata": {
        "id": "sSRTZZW4WQrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models \n",
        "\n",
        "model = models.alexnet(pretrained=True)\n",
        "model"
      ],
      "metadata": {
        "id": "lEaPbpU0WbeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compute similarities by model layer"
      ],
      "metadata": {
        "id": "yLA7-L4Aaajg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "from pathlib import Path \n",
        "from PIL import Image \n",
        "from fastprogress import progress_bar\n",
        "from feature_extractor import FeatureExtractor, get_layer_names\n",
        "\n",
        "@torch.no_grad()\n",
        "def compare_features(model, layer_names, batch):\n",
        "  model.eval()\n",
        "  RSM = {}\n",
        "  with FeatureExtractor(model, layer_names) as extractor:\n",
        "    features = extractor(batch)\n",
        "  \n",
        "  for layer_name,X in progress_bar(features.items()):\n",
        "    RSM[layer_name] = torch.corrcoef(X.flatten(1))\n",
        "  \n",
        "  return RSM"
      ],
      "metadata": {
        "id": "DBQE8n8daZ7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = get_layer_names(model)\n",
        "layer_names"
      ],
      "metadata": {
        "id": "ISoe8MfjWkWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [\n",
        " './face_stimuli_png/control_white_male.png',\n",
        " './face_stimuli_png/inverted_white_male.png',\n",
        " './face_stimuli_png/sheared_white_male.png',\n",
        "]\n",
        "imgs = [Image.open(img).convert('RGB') for img in images]\n",
        "batch = torch.stack([transform(img) for img in imgs])\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "id": "-Vdu9ISnXFCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [Path(fname).name for fname in images]\n",
        "filenames"
      ],
      "metadata": {
        "id": "r8alw1smdM2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "  (0,1,'control-vs-inverted'),\n",
        "  (0,2,'control-vs-sheared'),\n",
        "]\n",
        "pairs"
      ],
      "metadata": {
        "id": "ay8DNIwCdX8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs[0]"
      ],
      "metadata": {
        "id": "gbn-B9KkZWpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs[1]"
      ],
      "metadata": {
        "id": "PzRv-R7iZX37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs[2]"
      ],
      "metadata": {
        "id": "bw8gcHI9ZY6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RSM = compare_features(model, layer_names, batch)"
      ],
      "metadata": {
        "id": "hcNN0pvRbc53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['layer_num', 'layer_name', 'image1', 'image2', 'pair', 'pearsonr']\n",
        "df = pd.DataFrame(columns=columns)\n",
        "df"
      ],
      "metadata": {
        "id": "m_-IhMS6bjdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from pathlib import Path \n",
        "\n",
        "results = defaultdict(list)\n",
        "\n",
        "for layer_num,(layer_name,matrix) in enumerate(RSM.items()):\n",
        "  for idx1,idx2,pair in pairs:\n",
        "    image1 = filenames[idx1]\n",
        "    image2 = filenames[idx2]\n",
        "    pearsonr = matrix[idx1,idx2].item()\n",
        "\n",
        "    results['layer_num'].append(layer_num)\n",
        "    results['layer_name'].append(layer_name)\n",
        "    results['image1'].append(image1)\n",
        "    results['image2'].append(image2)\n",
        "    results['pair'].append(pair)\n",
        "    results['pearsonr'].append(pearsonr)\n",
        "\n",
        "df = pd.DataFrame(results, columns=columns)\n",
        "df"
      ],
      "metadata": {
        "id": "XC0h0nnwXowq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df[df.layer_num==0]"
      ],
      "metadata": {
        "id": "1G4iroKqhWTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.lineplot(data=df, x=\"layer_num\", y=\"pearsonr\", hue=\"pair\")\n",
        "ax.set_ylim([0,1.0])"
      ],
      "metadata": {
        "id": "zoZbnfP-YUEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F-hysi9VRO4Y"
      }
    }
  ]
}