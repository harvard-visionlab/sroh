{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sroh_boostrap_lesioning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNAsFC3ZAwyZwUkLfwtZDeC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caed0b26bc8a4ab89509f9b32b1a74e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98b721f8893f42208a3ccafdf91cf18d",
              "IPY_MODEL_fe099ed682054392bb4a95a78ed79635",
              "IPY_MODEL_fd39f74b4f634da0967125b68798f996"
            ],
            "layout": "IPY_MODEL_46128a07357b4037ae1fda941a6da370"
          }
        },
        "98b721f8893f42208a3ccafdf91cf18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39bd98e273fc4a8693515a954d479f29",
            "placeholder": "​",
            "style": "IPY_MODEL_0de29ed3ca1e479c9c0905d89a8112df",
            "value": "100%"
          }
        },
        "fe099ed682054392bb4a95a78ed79635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe6f4bd717848809b5dc89429843e18",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c406021291847148d9ca1768be86123",
            "value": 244408911
          }
        },
        "fd39f74b4f634da0967125b68798f996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854cd859da78477292a486ae2451f038",
            "placeholder": "​",
            "style": "IPY_MODEL_f80b5367f8f7475fa288dc59af9826e1",
            "value": " 233M/233M [00:01&lt;00:00, 154MB/s]"
          }
        },
        "46128a07357b4037ae1fda941a6da370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bd98e273fc4a8693515a954d479f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de29ed3ca1e479c9c0905d89a8112df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe6f4bd717848809b5dc89429843e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c406021291847148d9ca1768be86123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "854cd859da78477292a486ae2451f038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80b5367f8f7475fa288dc59af9826e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvard-visionlab/sroh/blob/main/2022/sroh_boostrap_lesioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruning Bootstrap\n",
        "\n",
        "To establish a random baseline, it would be nice to randomly shuffle our mask a large number of times (say 1000).\n",
        "\n",
        "A Naive approach would be just to run prune.random_unstructured(module, name=\"weight\", amount=0.3) 1000 times, but that would be slow!\n",
        "\n",
        "The biggest waist would be passing images through the model backbone (model.features) 1000 times, since the backbone isn't changing.\n",
        "\n",
        "So we could just \"save\" the output of the backbone, then pass it through the classifier 1000 times. This should be faster, but still could be slow. \n",
        "\n",
        "More generally, we'll want to setup two functions, one to handle the forward pass up to our \"pruning layer\", and then store the outputs for multiple passes from the pruning layer forward with different random masks. \n",
        "\n",
        "Below I implement a demo of this approach, and use it to benchmark about how long it would take to run on the full validation set."
      ],
      "metadata": {
        "id": "rl7wNvTPWSJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torch.nn.utils import prune\n",
        "from torch.nn.utils.prune import (\n",
        "    BasePruningMethod, \n",
        "    _validate_pruning_amount_init,\n",
        "    _validate_pruning_amount,\n",
        "    _compute_nparams_toprune\n",
        ")\n",
        "from torchvision import models\n",
        "from pdb import set_trace"
      ],
      "metadata": {
        "id": "_-E19zT8LyCu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = models.alexnet(pretrained=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "caed0b26bc8a4ab89509f9b32b1a74e2",
            "98b721f8893f42208a3ccafdf91cf18d",
            "fe099ed682054392bb4a95a78ed79635",
            "fd39f74b4f634da0967125b68798f996",
            "46128a07357b4037ae1fda941a6da370",
            "39bd98e273fc4a8693515a954d479f29",
            "0de29ed3ca1e479c9c0905d89a8112df",
            "8fe6f4bd717848809b5dc89429843e18",
            "1c406021291847148d9ca1768be86123",
            "854cd859da78477292a486ae2451f038",
            "f80b5367f8f7475fa288dc59af9826e1"
          ]
        },
        "id": "xZINOugyXYRO",
        "outputId": "0eee8e15-8e04-427e-d417-22259fc6bcac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caed0b26bc8a4ab89509f9b32b1a74e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lesion model.classifier[1]\n",
        "\n",
        "Let's say we're lesioning units in model.classifier[1]\n",
        "\n",
        "We'll need two functions, forward_before_prune, and forward_after_prune, which will basically split our model in two, such that:\n",
        "\n",
        "```\n",
        "out1 = forward_before_prune(model, image_batch)\n",
        "out = forward_after_prune(model, out1)\n",
        "```\n",
        "\n",
        "will give the same output as:\n",
        "```\n",
        "out model(image_batch)\n",
        "```\n",
        "\n",
        "So how do we do this splitting? We start by inspecting the forward pass of each module of the model.\n",
        "```\n",
        "model.forward??\n",
        "```\n",
        "\n",
        "and any submodules we need to subdivide further, e.g.,\n",
        "\n",
        "```\n",
        "model.classifier.forward??\n",
        "```\n"
      ],
      "metadata": {
        "id": "mFIqzlCPMbFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward??"
      ],
      "metadata": {
        "id": "KcRIfTpSpyRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier.forward??"
      ],
      "metadata": {
        "id": "DsY6m0McqCKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Within our custom functions, we refer to the model as \"self\" \n",
        "# (so that our forward functions read like the actual forward function of the \n",
        "# that you see when running `model.forward??`).\n",
        "\n",
        "# we need to write some functions to break the forward pass up into two steps\n",
        "# everything that happens before our pruned module, and everything\n",
        "# that happens after (including the pruned module)\n",
        "def forward_before_prune(self, x):\n",
        "  x = self.features(x)\n",
        "  x = self.avgpool(x)\n",
        "  x = torch.flatten(x, 1)\n",
        "  x = self.classifier[0](x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def forward_after_prune(self, x):\n",
        "  \n",
        "  x = self.classifier[1](x)\n",
        "  x = self.classifier[2](x)\n",
        "  x = self.classifier[3](x)\n",
        "  x = self.classifier[4](x)\n",
        "  x = self.classifier[5](x)\n",
        "  x = self.classifier[6](x)\n",
        "\n",
        "  return x  "
      ],
      "metadata": {
        "id": "tyfAI7Llp2Ya"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test to make sure your custom forward functions give \n",
        "# the same output as the original model\n",
        "\n",
        "x = torch.rand(10,3,224,224).to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  out1 = model(x)\n",
        "  out_before = forward_before_prune(model, x)\n",
        "  out2 = forward_after_prune(model, out_before)\n",
        "torch.allclose(out1, out2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWN88QfvqVA0",
        "outputId": "4b3f971b-ad0e-40de-efea-dcb512c22e5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gutl4nJSN3Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now run the pruning/lesioning bootstrap"
      ],
      "metadata": {
        "id": "hcDR3rrPN6rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "module = model.classifier[1]\n",
        "prune.random_unstructured(module, name=\"weight\", amount=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdvUBMIIocSu",
        "outputId": "535702cd-afe6-4865-daa6-1edbdd721589"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=9216, out_features=4096, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = model.classifier[1].weight_mask\n",
        "print(mask.sum() / mask.nelement())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-drRdpskAVJ",
        "outputId": "5c6db44b-8e46-4fb1-9f3b-d10b164add91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# our dummy batch to simulate how long things take for a batch of 256 images\n",
        "imgs = torch.rand(256,3,224,224).to(device)"
      ],
      "metadata": {
        "id": "hLt-6-RNXe35"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from fastprogress import master_bar, progress_bar \n",
        "\n",
        "start_time = time.time()\n",
        "percentages = np.array([.05, .10, .15, .30, .50, .70, .90])\n",
        "num_samples = 1000\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  before_features = forward_before_prune(model, imgs)\n",
        "  mask = module.weight_mask\n",
        "\n",
        "  # this new mask will get \"randomly filled\" with ones/zeros \n",
        "  # on each pass through nested loops below\n",
        "  new_mask = torch.empty(mask.nelement()).to(device)\n",
        "\n",
        "  # big savings here, by going through each mask percent\n",
        "  # and each number of samples without recomptuing features\n",
        "  # for this batch\n",
        "  mb = master_bar(percentages)\n",
        "  for pct_num,mask_pct in enumerate(mb):\n",
        "    for sample_num in progress_bar(range(num_samples), parent=mb):\n",
        "      # setting random seed based on mask_pct and sample_num\n",
        "      # to make sure every batch has the same mask for the same \n",
        "      # combination of mask_pct and sample number\n",
        "      torch.manual_seed(mask_pct + sample_num)\n",
        "\n",
        "      # the _ operators happen \"in place\" (memory efficient)\n",
        "      # we get random uniform numbers gretaer than mask_pct\n",
        "      new_mask.uniform_(0, 1).gt_(mask_pct)    \n",
        "\n",
        "      # copy (in place)   \n",
        "      model.classifier[1].weight_mask.copy_(new_mask.view(mask.size()))\n",
        "\n",
        "      # forward through the model\n",
        "      out = forward_after_prune(model, before_features.clone()) \n",
        "duration = time.time() - start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AdlOiXCLXlNp",
        "outputId": "28306809-ba38-4c7a-bad5-de09f401f319"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_total_seconds = duration * 50000 / 256 # 50k validation images, divided by batch size 256\n",
        "estimated_hrs = estimated_total_seconds / (3600) # 3600 seconds per hour\n",
        "print(f\"Estimated hours to run bootstrapped validation: {estimated_hrs:4.1f}hrs\")"
      ],
      "metadata": {
        "id": "NC-lrRMgpF_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496930fa-f529-416a-946d-1e806945f085"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated hours to run bootstrapped validation:  2.5hrs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FRCQQGrEPKvX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}